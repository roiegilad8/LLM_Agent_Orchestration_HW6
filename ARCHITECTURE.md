# Architecture Documentation

## Overview

This project implements a **Prompt Engineering Benchmark Framework** that compares the effectiveness of four prompt engineering techniques (Baseline, Few-Shot, Chain-of-Thought, and ReAct) across three LLM models (GPT-4o, Grok-2, and Perplexity).

The architecture follows a modular, extensible design that separates concerns and enables easy addition of new models, techniques, and evaluation metrics.

---

## System Context (C4 Level 1)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     External Systems                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚
â”‚  â”‚   OpenAI     â”‚  â”‚     xAI      â”‚  â”‚  Perplexity  â”‚           â”‚
â”‚  â”‚  (GPT-4o)    â”‚  â”‚  (Grok-2)    â”‚  â”‚  (Sonar)     â”‚           â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
â”‚         â–²                  â–²                  â–²                  â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â”‚
â”‚                            â”‚                                     â”‚
â”‚                    HTTP/REST API Calls                           â”‚
â”‚                            â”‚                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚  LLM Orchestration â”‚
                    â”‚    Framework       â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚  Prompt Engineering       â”‚
                    â”‚  Benchmark System         â”‚
                    â”‚  (Python 3.12)            â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚   Data Storage            â”‚
                    â”‚  (CSV, JSON, Images)      â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Container Architecture (C4 Level 2)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Prompt Engineering Benchmark                         â”‚
â”‚                                                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚                    Data Layer                                   â”‚  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚  â”‚
â”‚  â”‚  â”‚ Questions  â”‚  â”‚  Responses â”‚  â”‚  Ground Truth Data   â”‚     â”‚  â”‚
â”‚  â”‚  â”‚ (CSV)      â”‚  â”‚  (CSV)     â”‚  â”‚  (JSON/CSV)          â”‚     â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                    â–²                                    â”‚
â”‚                                    â”‚                                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚               Processing Layer (Python Core)                    â”‚  â”‚
â”‚  â”‚                                                                  â”‚  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                   â”‚  â”‚
â”‚  â”‚  â”‚ Prompt Builder   â”‚  â”‚ API Orchestrator â”‚                   â”‚  â”‚
â”‚  â”‚  â”‚  - Baseline      â”‚  â”‚  - GPT-4o        â”‚                   â”‚  â”‚
â”‚  â”‚  â”‚  - Few-Shot      â”‚  â”‚  - Grok-2        â”‚                   â”‚  â”‚
â”‚  â”‚  â”‚  - CoT           â”‚  â”‚  - Perplexity    â”‚                   â”‚  â”‚
â”‚  â”‚  â”‚  - ReAct         â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                          â”‚  â”‚
â”‚  â”‚                                                                  â”‚  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                   â”‚  â”‚
â”‚  â”‚  â”‚ Grading Engine   â”‚  â”‚ Analysis Module  â”‚                   â”‚  â”‚
â”‚  â”‚  â”‚  - Accuracy      â”‚  â”‚  - Metrics Calc  â”‚                   â”‚  â”‚
â”‚  â”‚  â”‚  - Fuzzy Match   â”‚  â”‚  - Aggregation   â”‚                   â”‚  â”‚
â”‚  â”‚  â”‚  - Validation    â”‚  â”‚  - Visualization â”‚                   â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                    â–²                                    â”‚
â”‚                                    â”‚                                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚                    Output Layer                                 â”‚  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚  â”‚
â”‚  â”‚  â”‚  CSV       â”‚  â”‚  PNG/JPEG  â”‚  â”‚  Markdown Reports    â”‚     â”‚  â”‚
â”‚  â”‚  â”‚  Reports   â”‚  â”‚  Charts &  â”‚  â”‚  Documentation       â”‚     â”‚  â”‚
â”‚  â”‚  â”‚            â”‚  â”‚  Visuals   â”‚  â”‚                      â”‚     â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Component Architecture (C4 Level 3)

### Core Modules

#### 1. **Data Preparation** (`data_prep_FINAL.py`)
Loads raw responses from 12 files (4 techniques Ã— 3 models) and creates standardized CSV datasets.

```
Input Files (12 TXT files)
      â†“
  Parse responses
      â†“
  Normalize format
      â†“
  results.csv (100 questions Ã— 12 columns)
  ground_truth.csv (100 answers)
```

**Key Functions:**
- `load_responses(filepath)` - Reads from TXT/CSV/JSON
- `combine_datasets()` - Merges 12 files
- Handles variable row counts (pads/trims to 100)

---

#### 2. **Grading Engine** (`compare_results_FIXED.py`)
Evaluates LLM responses against ground truth answers using fuzzy matching.

```
results.csv + ground_truth.csv
         â†“
  Comparison loop (100 questions)
         â†“
  Fuzzy match algorithm (similarity score)
         â†“
  Accuracy calculation (strict match)
         â†“
  graded_scores.csv
```

**Key Functions:**
- `fuzzy_match(response, expected)` - Uses difflib.SequenceMatcher
- `calculate_accuracy()` - Counts exact matches
- `grade_all_responses()` - Main grading loop

---

#### 3. **Analysis Module** (`compare_results_FIXED.py`)
Generates metrics, aggregations, and visualizations.

```
graded_scores.csv
         â†“
  Calculate metrics per combination
         â†“
  Aggregate by technique & model
         â†“
  Generate 4 visualizations (PNG)
  Generate 2 reports (CSV)
         â†“
  outputs/ (6 files)
```

**Key Functions:**
- `calculate_metrics()` - Mean accuracy, std dev per combo
- `generate_charts()` - Matplotlib visualizations
- `aggregate_results()` - Group by technique/model

---

#### 4. **Visualization Layer**
Creates 4 publication-ready charts:

| Chart | Purpose | X-axis | Y-axis |
|-------|---------|--------|--------|
| `accuracy_by_technique.png` | Compare prompt techniques | Technique | Accuracy (%) |
| `accuracy_by_model.png` | Compare LLM models | Model | Accuracy (%) |
| `model_technique_heatmap.png` | 2D comparison grid | Model Ã— Technique | Accuracy |
| `all_combinations.png` | All 12 combos ranked | Combination | Accuracy (%) |

---

## Data Flow Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     Data Processing Pipeline                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

PHASE 1: Data Preparation
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 12 TXT Files     â”‚
â”‚ (responses)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ data_prep_FINAL.py           â”‚
â”‚ - Load from results/GPT/      â”‚
â”‚ - Load from results/Grok/     â”‚
â”‚ - Load from results/Perplexityâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ results.csv (100 Ã— 14)       â”‚
â”‚ ground_truth.csv (100 Ã— 5)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

PHASE 2: Grading
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Comparison Loop  â”‚
â”‚ 100 iterations   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ compare_results_FIXED.py      â”‚
â”‚ - Fuzzy match each response   â”‚
â”‚ - Calculate accuracy          â”‚
â”‚ - Grade all 12 combinations   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ graded_scores.csv            â”‚
â”‚ (100 rows Ã— 14 columns)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

PHASE 3: Analysis & Output
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Analysis Module  â”‚
â”‚ - Metrics calc   â”‚
â”‚ - Aggregation    â”‚
â”‚ - Visualization  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ outputs/ (6 files)           â”‚
â”‚ - 4 PNG charts               â”‚
â”‚ - 2 CSV reports              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Directory Structure

```
LLM_Agent_Orchestration_HW6/
â”‚
â”œâ”€â”€ ğŸ“„ README.md                          # Project overview
â”œâ”€â”€ ğŸ“„ CONTRIBUTING.md                    # Development guide
â”œâ”€â”€ ğŸ“„ ARCHITECTURE.md                    # This file
â”œâ”€â”€ ğŸ“„ PROMPTS_LOG.md                     # Prompt documentation
â”œâ”€â”€ ğŸ“„ COST_ANALYSIS.md                   # Cost breakdown
â”‚
â”œâ”€â”€ ğŸ compare_results_FIXED.py          # Main analysis pipeline
â”œâ”€â”€ ğŸ data_prep_FINAL.py                # Data preparation script
â”‚
â”œâ”€â”€ ğŸ”§ pyproject.toml                     # Linting & formatting config
â”œâ”€â”€ ğŸ”§ .pre-commit-config.yaml            # Pre-commit hooks
â”œâ”€â”€ ğŸ”§ requirements.txt                   # Runtime dependencies
â”œâ”€â”€ ğŸ”§ requirements-dev.txt               # Dev dependencies
â”œâ”€â”€ ğŸ”§ .env.example                       # Environment template
â”‚
â”œâ”€â”€ ğŸ“ .github/
â”‚   â””â”€â”€ workflows/
â”‚       â””â”€â”€ ci-cd.yml                     # CI/CD pipeline
â”‚
â”œâ”€â”€ ğŸ“ results/
â”‚   â”œâ”€â”€ GPT/                              # GPT-4o responses (12 files)
â”‚   â”œâ”€â”€ Grok/                             # Grok-2 responses (12 files)
â”‚   â”œâ”€â”€ Perplexity/                       # Perplexity responses (12 files)
â”‚   â”œâ”€â”€ RESULTS.md                        # Summary document
â”‚   â””â”€â”€ prompts_log/
â”‚       â””â”€â”€ PROMPTS_LOG.md                # Prompt templates & examples
â”‚
â”œâ”€â”€ ğŸ“ outputs/
â”‚   â”œâ”€â”€ graded_scores.csv                 # All 100 questions graded
â”‚   â”œâ”€â”€ detailed_metrics.csv              # Accuracy per combination
â”‚   â”œâ”€â”€ accuracy_by_technique.png         # Bar chart: techniques
â”‚   â”œâ”€â”€ accuracy_by_model.png             # Bar chart: models
â”‚   â”œâ”€â”€ model_technique_heatmap.png       # 2D heatmap
â”‚   â””â”€â”€ all_combinations.png              # Ranked bar chart (12 combos)
â”‚
â””â”€â”€ ğŸ“ docs/ (optional, for screenshots/diagrams)
    â””â”€â”€ screenshots/                      # Visual documentation
```

---

## Module Dependencies

```
data_prep_FINAL.py
    â”‚
    â””â”€â”€ pandas
    â””â”€â”€ os
    â””â”€â”€ json

compare_results_FIXED.py
    â”‚
    â”œâ”€â”€ pandas                    # CSV/JSON handling
    â”œâ”€â”€ difflib                   # Fuzzy matching
    â”œâ”€â”€ matplotlib                # Chart generation
    â””â”€â”€ numpy                     # Array operations

External APIs (via HTTP)
    â”‚
    â”œâ”€â”€ OpenAI API (GPT-4o)
    â”œâ”€â”€ xAI API (Grok-2)
    â””â”€â”€ Perplexity API (Sonar)

Quality Standards
    â”‚
    â”œâ”€â”€ Black                     # Code formatting
    â”œâ”€â”€ Ruff                      # Linting
    â”œâ”€â”€ isort                     # Import sorting
    â”œâ”€â”€ pytest                    # Testing
    â””â”€â”€ mypy                      # Type checking
```

---

## Key Design Decisions (ADRs)

### ADR-1: Fuzzy Matching for Grading
**Decision:** Use Python's `difflib.SequenceMatcher` for similarity scoring.

**Rationale:**
- Handles typos and formatting variations
- Better than strict string equality
- No external library dependency
- Fast for 100 questions

**Trade-off:** May give partial credit to wrong answers. Mitigated by using both fuzzy score and exact match.

---

### ADR-2: CSV as Primary Storage
**Decision:** Use CSV for results and outputs instead of JSON.

**Rationale:**
- Human-readable in Excel/spreadsheets
- Easy to filter, sort, and analyze
- Standard for academic reporting
- Reduces data pipeline complexity

**Trade-off:** Less hierarchical than JSON. Mitigated by careful schema design.

---

### ADR-3: Modular Script Architecture
**Decision:** Two separate scripts (`data_prep_FINAL.py` and `compare_results_FIXED.py`) instead of single monolithic script.

**Rationale:**
- Separation of concerns (prepare vs. analyze)
- Easier to test and debug
- Can re-run analysis without re-fetching from APIs
- Clear data dependencies

**Trade-off:** Requires running two scripts in sequence. Mitigated by clear documentation.

---

### ADR-4: Matplotlib for Visualizations
**Decision:** Use Matplotlib instead of Plotly or Seaborn.

**Rationale:**
- Lightweight, no JavaScript required
- Publication-ready static images (PNG)
- Works in CI/CD pipelines
- Wide compatibility

**Trade-off:** Less interactive than Plotly. Acceptable for academic use.

---

## Extensibility Points

### Adding a New Prompt Technique

1. Create responses with new technique (e.g., `chain_of_verification.txt`)
2. Place in `results/GPT/chain_of_verification_GPT.txt`, etc.
3. Update `data_prep_FINAL.py` to include in file list:
   ```python
   'ChainOfVerification': 'results/GPT/chain_of_verification_GPT.txt'
   ```
4. Re-run: `python data_prep_FINAL.py && python compare_results_FIXED.py`

### Adding a New Model

1. Create response files for all 4 techniques
2. Place in new folder: `results/NewModel/`
3. Update file lists in `data_prep_FINAL.py`
4. Charts automatically update

### Adding a New Metric

1. Add calculation function in `compare_results_FIXED.py`:
   ```python
   def calculate_f1_score(graded_df):
       # Implementation
       return f1_scores
   ```
2. Add to output CSV generation
3. Visualize in charts

---

## Performance Characteristics

| Operation | Time | Resources |
|-----------|------|-----------|
| Data Preparation (12 files, 100 Qs) | ~2 sec | 50 MB RAM |
| Grading (Fuzzy match, 100 Qs Ã— 12 combos) | ~5 sec | 100 MB RAM |
| Analysis & Visualization (4 charts, 2 CSVs) | ~3 sec | 150 MB RAM |
| **Total Pipeline** | **~10 sec** | **~200 MB RAM** |

---

## Testing Strategy

### Unit Tests (Using pytest)
- `test_grading.py` - Fuzzy match accuracy, exact match calculation
- `test_analysis.py` - Metrics aggregation, chart generation
- `test_data_prep.py` - File loading, data normalization

### Integration Tests
- Full pipeline: data_prep â†’ compare_results
- CSV schema validation
- Chart PNG generation

### Quality Standards
- **Code Coverage:** Target â‰¥80%
- **Linting:** Ruff + Black pass without errors
- **Type Checking:** mypy with strict settings
- **Pre-commit:** All hooks pass before commit

### CI/CD Pipeline
- Runs on every push to `main` or `develop`
- Linting â†’ Testing â†’ Coverage â†’ Build check
- Fails if coverage < 70%

---

## Future Improvements

1. **Parallel API Calls:** Currently sequential. Use `asyncio` for parallel requests.
2. **Caching:** Cache API responses to avoid re-calling during development.
3. **Web Dashboard:** Interactive visualization via Flask/Streamlit.
4. **Database:** Store results in PostgreSQL instead of CSV for querying.
5. **Prompt Versioning:** Track prompt iterations and their impact on accuracy.
6. **Cost Optimization:** Implement token counting to predict costs before running.

---

## References

- **C4 Model:** https://c4model.com/
- **Prompt Engineering:** https://platform.openai.com/docs/guides/prompt-engineering
- **Fuzzy Matching:** Python `difflib` documentation
- **CI/CD:** GitHub Actions documentation
- **Code Quality:** Black, Ruff, pytest documentation

---

**Last Updated:** December 15, 2025  
**Author:** LLM Orchestration HW6 Team
